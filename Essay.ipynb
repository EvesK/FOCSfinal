{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Free Grammar Parsing using the CYK Algorithm\n",
    "## Muya Guoji and Evelyn Kessler\n",
    "## December 17, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "    1. [What is CFG Parsing?](#subintroduction1)\n",
    "    2. [CFG Parsing in the Real World](#subintroduction2)\n",
    "2. [The CYK Algorithm](#paragraph1)\n",
    "    1. [Chomsky Normal Form](#subparagraph11)\n",
    "    2. [Converting CFGs into Chomsky Normal Form (CNF)](#subparagraph12)\n",
    "    3. [Basic Code Architecture](#subparagraph13)\n",
    "    4. [Uses in the World](#subparagraph14)\n",
    "3. [Code Walkthrough](#paragraph2) - Muya\n",
    "\n",
    "4. [CYK Parsing on Natural Langauge](#paragraph3)\n",
    "    1. [Benefits of CYK over Transformers](#subparagraph31)\n",
    "    2. [What are Parts of Speech?](#subparagraph32)\n",
    "    3. [Writing CNF CFGs for Natural Language Parsing](#subparagraph33)\n",
    "    4. [Visual Walkthrough: Parsing a Sentence](#subparagraph34) - Evelyn\n",
    "5. [Appendix](#appendix)\n",
    "    1. [Instructions for Running the Algorithm](#subappendix1) - see 2.2 for how to write CNF CFGs, once you have one put it here and also you can use our examples by changing out this line - Evelyn\n",
    "    2. [Example CFGs and strings to parse](#subappendix2) - Muya (if you want to create your own, see 2.2)\n",
    "    3. [CYK Implementation](#subappendix3) - call file, have some examples of it running - Evelyn\n",
    "6. [Sources](#sources) - MLA format - Evelyn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction <a name=\"introduction\"></a>\n",
    "A context free grammar, or CFG, is a grammar that is used to generate all possible strings in a given language. A context free grammar, G, can be defined by a tuple \n",
    "\n",
    "$$\n",
    "G = (\\Sigma, \\Gamma, R, S)\n",
    "$$\n",
    "\n",
    "where $\\Sigma$ is a list of terminal symbols, $\\Gamma$ is a list of non-terminal symbols, R is a list of rules of the form $x \\rightarrow \\mu$ where $\\mu \\in (\\Gamma \\cup \\Sigma)*$, and $S$ is the start symbol. One way of defining a language is to write a CFG for that language. Then, we can find for any string whether that string is in the language by evaluating whether the rules of the CFG could possibly generate that string. For this method we start with the start symbol $S$ and apply the rules continuously until we generate the desired string. If we can't generate the string after (a reasonable number of) rules applications *double check this is actually right; are CFGs where you get stuck or where you run out??*, we can conclude that the given string is not valid for the language described by that CFG.\n",
    "\n",
    "##### What is CFG Parsing? <a name=\"subintroduction1\"></a>\n",
    "CFG parsing is a method used to determine if a given string conforms to the rules of a specific language as defined by its CFG. Unlike the previous CFG method, which begins with the start symbol and attempts to construct the string by applying grammar rules, CFG parsing starts with the given string and works backwards, trying to decompose it into its basic elements until it reaches the start symbol. This process involves applying the CFG rules in reverse.\n",
    "\n",
    "CFG parsing can be implemented with several different strategies and algorithms. These include top-down parsing methods like recursive descent parsing, where the parser starts at the highest level of the grammar and works its way down, and bottom-up methods like shift-reduce parsing, which start with the input and gradually transform it into the syntax tree of the grammar.\n",
    "\n",
    "The essential part of CFG parsing is the construction of a parse tree or syntax tree. This tree represents the syntactic structure of the string according to the grammar rules. Each node in the tree corresponds to a grammar rule, and the leaves represent the elements of the string. By analyzing the tree, we can understand how the string is structured according to the grammar and whether it's a valid construct in the language.\n",
    "\n",
    "CFG parsing is crucial in various applications because it allows for the automatic analysis of the structure of strings, which is fundamental in language processing, programming languages, and other computational linguistics areas. It enables computers to understand and manipulate complex structures in human and programming languages, making it a cornerstone of modern computing.\n",
    "\n",
    "##### CFG Parsing in the Real World <a name=\"subintroduction2\"></a>\n",
    "CFG parsing is valuable in many practical scenarios, particularly in computer science and linguistics. A prime example is in natural language processing (NLP), where CFG parsing helps computers make sense of human language. It breaks down sentences into grammatical parts, which is crucial for things like translating languages since computers need to get the structure right to translate words accurately from one language to another. Another key use of CFG parsing is in building compilers for programming languages. Compilers use CFG to dissect the code that programmers write, turning it into something a computer can understand and act on.\n",
    "\n",
    "Besides these, CFG parsing finds its place in various other areas such as:\n",
    "- Checking code for errors in programming tools.\n",
    "- Helping voice recognition systems understand what we say.\n",
    "- Improving writing software by checking for grammatical mistakes.\n",
    "- Analyzing complex mathematical formulas in scientific programs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The CYK Algorithm <a name=\"paragraph1\"></a>\n",
    "\n",
    "##### Chomsky Normal Form <a name=\"subparagraph11\"></a>\n",
    "Before delving into the algorithm, we would like to first touch on the concept of Chomsky Normal Form (CNF). It is a prerequisite for understanding the CYK algorithm, as the algorithm specifically requires grammars to be in CNF in order to be processed. \n",
    "\n",
    "CNF, developed by the well-known modern linguist Noam Chomsky, aims to simplify the rules of context-free\n",
    "grammars for more efficient parsing and algorithmic analysis. It is a specific method for expressing CFGs, wherein every production rule takes one of two forms: either a non-terminal symbol producing two other non-terminal symbols or a non-terminal symbol producing a single terminal symbol. This single terminal symbol may include epsilon, indicating the deletion of a sentence. \n",
    "\n",
    "$$\n",
    "A \\rightarrow BC\n",
    "$$\n",
    "$$\n",
    "A \\rightarrow a\n",
    "$$\n",
    "$$\n",
    "S \\rightarrow \\Epsilon\n",
    "$$\n",
    "*(Uppercase letters represent non-terminal symbols, and lowercase letters represent terminal symbols)*\n",
    "\n",
    "\n",
    "By unifying production rules in such a specific and clean form really simplifies the design and analysis of parsing\n",
    "algorithms like CYK. \n",
    "\n",
    "##### Converting CFGs into Chomsky Normal Form (CNF) <a name=\"subparagraph33\"></a>\n",
    "\n",
    "In CNF, each rule must either produce two non-terminal symbols or a single terminal symbol. Consider the grammars below.\n",
    "\n",
    "$$G1 = S \\rightarrow a, S \\rightarrow AZ, A \\rightarrow a, Z \\rightarrow z$$\n",
    "$$G2 = S \\rightarrow a, S \\rightarrow aZ, Z \\rightarrow a$$\n",
    "\n",
    "Grammar $G1$ is in CNF since the first, third, and fourth rules all produce a single terminal symbol and the second rule produces two non-terminal symbols. Grammar $G2$ is not in CNF since the rule $S \\rightarrow aZ$ contains a terminal symbol ($a$) followed by a non-terminal symbol ($Z$).\n",
    "\n",
    "To convert a CFG to CNF, follow these rules:\n",
    "\n",
    "1. **Eliminate the start symbol from right hand side (RHS)**: If there is a start symbol S in the RHS of any rule, create a new rule $S0 \\rightarrow S$ and replace the $S$ in the RHS with $S0$.\n",
    "\n",
    "2. **Eliminate Null Productions**: Remove any rules that produce an empty string, replacing them with alternative productions that achieve the same language representation without the null option.\n",
    "\n",
    "3. **Eliminate Unit Productions**: Replace rules that produce a single non-terminal with rules that produce terminals directly. For instance $A \\rightarrow B$ and $B \\rightarrow a$ can be replaced with $A \\rightarrow a$.\n",
    "\n",
    "4. **Ensure all rules with terminals in RHS have a single terminal**: Eliminate terminals from the RHS if they are with other terminals or non-terminals by decomposing into multiple rules. For example, if you have the rule $X \\rightarrow xY$ you can decompose it into $X \\rightarrow ZY$ and $Z \\rightarrow x$.\n",
    "\n",
    "5. **Ensure all rules with non-terminals in RHS have exactly two non-terminals** : Eliminate rules with more than two non-terminal symbols by decomposing them into multiple rules. For example, the rule $X \\rightarrow XYZ$ can be broken into $X \\rightarrow PZ$ and $P \\rightarrow XY$.\n",
    "\n",
    "Let's try an example. The grammar $S \\rightarrow \\epsilon, S \\rightarrow aSb$ generates the language $a^nb^n | n \\geq 0$.\n",
    "\n",
    "1. Eliminate start symbols from the right hand side.\n",
    "We can eliminate the S from the RHS by writing a new rule $S0 \\rightarrow S$ where S0 is our new start symbol.\n",
    "\n",
    "$$S \\rightarrow \\epsilon$$\n",
    "$$S \\rightarrow aSb$$\n",
    "$$S0 \\rightarrow S$$\n",
    "\n",
    "2. Eliminate Null Productions\n",
    "Let's remove the epsilon and add a rule to cover the case where the $S \\rightarrow \\epsilon$ would be used. If this rule were used, the $\\epsilon$ would replace the $T$ in $S \\rightarrow aTb$ leaving just the $a$ and $b$. We can replicate this behavior by declaring $S \\rightarrow ab$. Note that this does not cover the case where $n=0$. To cover this case, we need to add back in a rule $S \\rightarrow \\epsilon$.\n",
    "\n",
    "$$S \\rightarrow ab$$\n",
    "$$S \\rightarrow aSb$$\n",
    "$$S \\rightarrow \\epsilon$$\n",
    "$$S0 \\rightarrow S$$\n",
    "\n",
    "3. Eliminate Unit Productions\n",
    "We have one unit production in our grammar, $S0 \\rightarrow S$. We can fix this by explicitely defining what $S0$ can go to as $S0 \\rightarrow ab | aSb | \\epsilon$. Note that $S0$ can go to $\\epsilon$ to create the empty string, but $S$ no longer goes to $\\epsilon$ since we've replaced that case.\n",
    "\n",
    "$$S \\rightarrow ab | aSb$$\n",
    "$$S0 \\rightarrow ab | aSb | \\epsilon$$\n",
    "\n",
    "4. Ensure all rules with terminals in RHS have a single terminal\n",
    "The rules $S \\rightarrow aSb$ and $S \\rightarrow ab$ have multiple terminals and/or terminals with non-terminals, as do their $S0$ equivalents. We can decompose them by introducing new non-terminals, $A \\rightarrow a$ and $B \\rightarrow b$.\n",
    "\n",
    "$$S \\rightarrow AB | ASB$$\n",
    "$$S0 \\rightarrow AB | ASB | \\epsilon$$\n",
    "$$A \\rightarrow a$$\n",
    "$$B \\rightarrow b$$\n",
    "\n",
    "5. Ensure all rules with non-terminals in RHS have exactly two non-terminals\n",
    "The rules $S \\rightarrow ASB$ and $S0 \\rightarrow ASB$ have three non-terminals. We can introduce a new non-terminal to split the rule into $S \\rightarrow AR$ and $R \\rightarrow SB$ and same for $S0$.\n",
    "\n",
    "$$S \\rightarrow AB | AR$$\n",
    "$$S0 \\rightarrow AB | AR | \\epsilon$$\n",
    "$$R \\rightarrow SB$$\n",
    "$$A \\rightarrow a$$\n",
    "$$B \\rightarrow b$$\n",
    "\n",
    "After covering the five steps, we've converted our CFG into CNF! Note that this is not the only possible CNF for this language, there are many options that will work.\n",
    "Let's double check that our CNF CFG makes sense for the language $a^nb^n | n \\geq 0$ using our parser!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a found in ('A', {'a'}). Adding A to T[0][0]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), set()]\n",
      "[set(), set(), set(), set()]\n",
      "[set(), set(), set(), set()]\n",
      "[set(), set(), set(), set()]\n",
      "a found in ('A', {'a'}). Adding A to T[1][1]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), set()]\n",
      "[set(), {'A'}, set(), set()]\n",
      "[set(), set(), set(), set()]\n",
      "[set(), set(), set(), set()]\n",
      "b found in ('B', {'b'}). Adding B to T[2][2]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), set()]\n",
      "[set(), {'A'}, set(), set()]\n",
      "[set(), set(), {'B'}, set()]\n",
      "[set(), set(), set(), set()]\n",
      "b found in ('B', {'b'}). Adding B to T[3][3]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), set()]\n",
      "[set(), {'A'}, set(), set()]\n",
      "[set(), set(), {'B'}, set()]\n",
      "[set(), set(), set(), {'B'}]\n",
      "A found in T[1][1] and B found in T[2][2]. S : AB is valid. Adding S to T[1][2]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), set()]\n",
      "[set(), {'A'}, {'S'}, set()]\n",
      "[set(), set(), {'B'}, set()]\n",
      "[set(), set(), set(), {'B'}]\n",
      "A found in T[1][1] and B found in T[2][2]. T : AB is valid. Adding T to T[1][2]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), set()]\n",
      "[set(), {'A'}, {'S', 'T'}, set()]\n",
      "[set(), set(), {'B'}, set()]\n",
      "[set(), set(), set(), {'B'}]\n",
      "T found in T[1][2] and B found in T[3][3]. R : TB is valid. Adding R to T[1][3]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), set()]\n",
      "[set(), {'A'}, {'S', 'T'}, {'R'}]\n",
      "[set(), set(), {'B'}, set()]\n",
      "[set(), set(), set(), {'B'}]\n",
      "A found in T[0][0] and R found in T[1][3]. S : AR is valid. Adding S to T[0][3]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), {'S'}]\n",
      "[set(), {'A'}, {'S', 'T'}, {'R'}]\n",
      "[set(), set(), {'B'}, set()]\n",
      "[set(), set(), set(), {'B'}]\n",
      "A found in T[0][0] and R found in T[1][3]. T : AR is valid. Adding T to T[0][3]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), {'S', 'T'}]\n",
      "[set(), {'A'}, {'S', 'T'}, {'R'}]\n",
      "[set(), set(), {'B'}, set()]\n",
      "[set(), set(), set(), {'B'}]\n",
      "Table filled. Checking if {'S', 'T'} (T[0][3]) contains S\n",
      "Can the string be derived? True\n"
     ]
    }
   ],
   "source": [
    "from CYKalgorithm import CYK_parse\n",
    "\n",
    "grammar_anbn = {\n",
    "    'S': {'AB', 'AR', 'e'}, #S: start sym. note that we've replaced S0 with S and S with T.\n",
    "    'T': {'AB', 'AR'},\n",
    "    'R': {'TB'},\n",
    "    'A': {'a'},\n",
    "    'B': {'b'}\n",
    "}\n",
    "\n",
    "# Example strings (TRUE)\n",
    "string_anbn = \"aabb\"\n",
    "string1_abnb = \"\"\n",
    "string2_anbn = \"ab\"\n",
    "\n",
    "# Example strings (FALSE)\n",
    "string3_anbn = \"abbb\"\n",
    "string4_anbn = \"b\"\n",
    "string5_anbn = \"abab\"\n",
    "\n",
    "table, result = CYK_parse(grammar_anbn, string_anbn) #change the string entry to other example string#_anbn to see different results, or add your own string!\n",
    "print(\"Can the string be derived?\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Code Architecture <a name=\"subparagraph12\"></a>\n",
    "Let's begin the code run-through of the algorithm with a high-level overview of the CYK algorithm's architecture:\n",
    "\n",
    "1. Input and Grammar Preparation: The algorithm starts with an input string, which are sentences breaking down into words, and a set of grammar rules in Chomsky Normal Form (CNF).\n",
    "\n",
    "2. Table Initialization: A table (matrix) is created with dimensions based on the length of the input string. This table will be used to store possible grammar derivations for substrings of the input.\n",
    "\n",
    "3. Table Filling: starting from the bottom level, the algorithm fills in the table and moves upward gradually. Each cell in the table represents a substring of the sentence and is filled with all possible grammar rules that could generate that substring. \n",
    "\n",
    "4. Combining Substrings: As it moves up the table, the algorithm combines smaller substrings that have already been matched with grammar rules to form larger substrings. It checks to see if these larger substrings can be generated by any of the CFG rules.\n",
    "\n",
    "5. Final Verification: Once the table is filled, the algorithm checks the top cell , which represents the entire string (sentence). If this cell contains the start symbol of the grammar, the string is considered derivable from the given grammar.\n",
    "\n",
    "6. Result and Visualization: Visualization of the table after each iteration can be used to enhance clarity and explainability of the processes for model implementers.\n",
    "\n",
    "##### Uses in the World <a name=\"subparagraph13\"></a>\n",
    "The CYK algorithm has several practical applications in the real world and is one of the most common CFG parsing algorithms. In computational linguistics, the CYK algorithm is used for parsing natural language sentences. It helps in syntactic analysis, which is fundamental for tasks like sentiment analysis (determining emotional tone behind a body of text), information extraction (finding specific information in a body of text), and automated question answering. This application is crucial for developing sophisticated AI chatbots and virtual assistants that can understand and respond to human language effectively.\n",
    "\n",
    "In the realm of programming, the CYK algorithm is employed in the development of compilers and interpreters for programming languages. Its ability to parse context-free grammars makes it useful for syntax analysis, ensuring that the code written by programmers adheres to the grammatical rules of the programming language. This aspect is vital for error detection and correction during software development.\n",
    "\n",
    "Additionally, in more specialized areas, the CYK algorithm can be applied in DNA sequencing and bioinformatics for analyzing and interpreting the genetic information contained in DNA sequences, where the algorithm helps in understanding the complex structures and patterns within genetic data. \n",
    "\n",
    "As we can see, the CYK algorithm has many uses in practical scenarios in computer science, math, technology, and even biology and other fields.\n",
    "\n",
    "##### Visual Walkthrough <a name=\"subparagraph14\"></a>\n",
    "\n",
    "Let's do a quick walkthrough of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Walkthrough <a name=\"paragraph2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CYK Parsing on Natural Langauge<a name=\"paragraph3\"></a>\n",
    "\n",
    "##### The Benifits of CYK in NLP and a Comparative Analysis with Transformers <a name=\"subparagraph31\"></a>\n",
    "Natural Language Processing (NLP) is a field is an interdisciplinary subfield of computer science and linguistics. that is primarily concerned with giving computers the ability to support and manipulate human language (*Wikipedia*). It encompasses a range of algorithmic tools for enabling computers to understand and process human language. Among these tools are transformers and the CYK algorithm.\n",
    "\n",
    "With the development and hype surrounding many large language models, transformers have garnered significant worldwide attention, possibly a byproduct of their attention mechanisms. While transformers are powerful tools in NLP, their approach to understanding language is based on statistical learning from large datasets. They are highly effective in many contexts *but might not always align perfectly with the complexities of human language understanding*. On the other hand, the CYK algorithm, with its basis in formal grammar theory, offers a more rule-based approach to parsing language. It can break down sentences into their grammatical components, making CYK particularly valuable in applications where precise syntax parsing is crucial, such as in compiling programming languages or in certain aspects of natural language understanding where the exact structure of sentences is significant. \n",
    "\n",
    "Which brings us to the next topic: parts of speech. \n",
    "\n",
    "##### Part of Speech <a name=\"subparagraph32\"></a>\n",
    "In NLP and any linguistics domain, parts of speech is a key terminology. Part of speech refers to a category of words with similar grammatical properties. Words in the same part of speech play similar roles in sentences and share similar rules of grammar. The main parts of speech in English include nouns, pronouns, verbs, adjectives, prepositions and so on. Identifying parts of speech and aligning substrings with these parts are the main preparations to enable the CYK algorithm to analyze sentence structure. \n",
    "\n",
    "For instance, with a suitable context-free grammar provided in Chomsky Normal Form (CNF) that shows 'blue' as an adjective, 'bird' as a noun, 'sings' as a verb, 'happily' as an adverb, 'in' as a preposition, 'the' as a definite article, and 'spring' as a noun, the CYK algorithm can determine whether a sentence like 'The blue bird sings happily in the spring' is structurally valid according to that grammar.\n",
    "\n",
    "##### Writing CNF CFGs for Natural Language Parsing <a name=\"subparagraph33\"></a>\n",
    "\n",
    "Writing a Context-Free Grammar (CFG) in Chomsky Normal Form (CNF) for parsing natural language sentences involves restructuring complex linguistic rules into a binary format. For instance, consider the simple sentence \"The cat sleeps.\" A basic CFG to parse this might look like:\n",
    "$$S \\rightarrow (NP)(VP)$$\n",
    "$$NP \\rightarrow (Det)(Noun)$$\n",
    "$$VP \\rightarrow Verb$$\n",
    "$$Det \\rightarrow \"The\"$$\n",
    "$$Noun \\rightarrow \"cat\"$$\n",
    "$$Verb \\rightarrow \"sleeps\"$$\n",
    "\n",
    "The abbreviations represent grammatical categories or parts of speech, where:\n",
    "\n",
    "**NP** stands for \"Noun Phrase.\" A noun phrase is a grammatical unit that can include a noun along with accompanying modifiers, such as articles, adjectives, pronouns, or other nouns. In the sentence \"The cat sleeps,\" \"The cat\" is an example of a noun phrase.\n",
    "\n",
    "**VP** represents \"Verb Phrase.\" A verb phrase consists of a main verb and, optionally, an object, and other modifiers. It can express actions, events, or states of being. In \"The cat sleeps,\" \"sleeps\" forms a simple verb phrase.\n",
    "\n",
    "**Det** is short for \"Determiner.\" Determiners are words that come before nouns and provide context in terms of definiteness, proximity, quantity, or ownership. Examples include \"the,\" \"a,\" \"this,\" \"those,\" \"many,\" etc. In the example sentence, \"The\" is a determiner.\n",
    "\n",
    "**Noun** is a word that identifies a person, place, thing, or idea. Nouns can function as the subject or object of a verb. In \"The cat sleeps,\" \"cat\" is the noun.\n",
    "\n",
    "**Verb** refers to a word that describes an action, state, or occurrence. Verbs form the main part of the predicate of a sentence. In the example, \"sleeps\" is the verb.\n",
    "\n",
    "Notice that our grammar is not yet in Chomsky Normal Form. We can convert it to CNF by applying the process described in *Converting CFGs into Chomsky Normal Form (CNF)*.\n",
    "\n",
    "##### Visual Walkthrough: Parsing a Sentence <a name=\"subparagraph34\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix <a name=\"appendix\"></a>\n",
    "\n",
    "##### Instructions for Running the Algorithm <a name=\"subappendix1\"></a>\n",
    "\n",
    "##### Example CFGs and Strings to Parse <a name=\"subappendix3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add examples here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CYK Implementation <a name=\"subappendix2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add CYK running here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources <a name=\"sources\"></a>\n",
    "https://jayd.ml/algorithms/chomsky.html\n",
    "https://www.geeksforgeeks.org/converting-context-free-grammar-chomsky-normal-form/\n",
    "https://www.geeksforgeeks.org/what-is-context-free-grammar/\n",
    "https://www.geeksforgeeks.org/cyk-algorithm-for-context-free-grammar/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
