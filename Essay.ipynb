{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Free Grammar Parsing using the CYK Algorithm\n",
    "## Muya Guoji and Evelyn Kessler\n",
    "## December 17, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "    1. [What is CFG Parsing?](#subintroduction1)\n",
    "    2. [CFG Parsing in the Real World](#subintroduction2)\n",
    "2. [The CYK Algorithm](#paragraph1)\n",
    "    1. [Chomsky Normal Form](#subparagraph11)\n",
    "    2. [Converting CFGs into Chomsky Normal Form (CNF)](#subparagraph12)\n",
    "    3. [Basic Code Architecture](#subparagraph13)\n",
    "    4. [Uses in the World](#subparagraph14)\n",
    "3. [Code Walkthrough](#paragraph2)\n",
    "\n",
    "4. [CYK Parsing on Natural Langauge](#paragraph3)\n",
    "    1. [Benefits of CYK over Transformers](#subparagraph31)\n",
    "    2. [What are Parts of Speech?](#subparagraph32)\n",
    "    3. [Writing CNF CFGs for Natural Language Parsing](#subparagraph33)\n",
    "    4. [Parsing a Sentence Walkthrough](#subparagraph34)\n",
    "5. [Appendix](#appendix)\n",
    "    1. [Instructions for Running the Algorithm](#subappendix1)\n",
    "    2. [Example CFGs and strings to parse](#subappendix2) - Muya\n",
    "    3. [CYK Implementation](#subappendix3)\n",
    "6. [Sources](#sources) - MLA format - Evelyn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction <a name=\"introduction\"></a>\n",
    "A context free grammar, or CFG, is a grammar that is used to generate all possible strings in a given language. A context free grammar, G, can be defined by a tuple \n",
    "\n",
    "$$\n",
    "G = (\\Sigma, \\Gamma, R, S)\n",
    "$$\n",
    "\n",
    "where $\\Sigma$ is a list of terminal symbols, $\\Gamma$ is a list of non-terminal symbols, R is a list of rules of the form $x \\rightarrow \\mu$ where $\\mu \\in (\\Gamma \\cup \\Sigma)*$, and $S$ is the start symbol. One way of defining a language is to write a CFG for that language. Then, we can find for any string whether that string is in the language by evaluating whether the rules of the CFG could possibly generate that string. For this method we start with the start symbol $S$ and apply the rules continuously until we generate the desired string. If we can't generate the string after (a reasonable number of) rules applications *double check this is actually right; are CFGs where you get stuck or where you run out??*, we can conclude that the given string is not valid for the language described by that CFG.\n",
    "\n",
    "##### What is CFG Parsing? <a name=\"subintroduction1\"></a>\n",
    "CFG parsing is a method used to determine if a given string conforms to the rules of a specific language as defined by its CFG. Unlike the previous CFG method, which begins with the start symbol and attempts to construct the string by applying grammar rules, CFG parsing starts with the given string and works backwards, trying to decompose it into its basic elements until it reaches the start symbol. This process involves applying the CFG rules in reverse.\n",
    "\n",
    "CFG parsing can be implemented with several different strategies and algorithms. These include top-down parsing methods like recursive descent parsing, where the parser starts at the highest level of the grammar and works its way down, and bottom-up methods like shift-reduce parsing, which start with the input and gradually transform it into the syntax tree of the grammar.\n",
    "\n",
    "The essential part of CFG parsing is the construction of a parse tree or syntax tree. This tree represents the syntactic structure of the string according to the grammar rules. Each node in the tree corresponds to a grammar rule, and the leaves represent the elements of the string. By analyzing the tree, we can understand how the string is structured according to the grammar and whether it's a valid construct in the language.\n",
    "\n",
    "CFG parsing is crucial in various applications because it allows for the automatic analysis of the structure of strings, which is fundamental in language processing, programming languages, and other computational linguistics areas. It enables computers to understand and manipulate complex structures in human and programming languages, making it a cornerstone of modern computing.\n",
    "\n",
    "##### CFG Parsing in the Real World <a name=\"subintroduction2\"></a>\n",
    "CFG parsing is valuable in many practical scenarios, particularly in computer science and linguistics. A prime example is in natural language processing (NLP), where CFG parsing helps computers make sense of human language. It breaks down sentences into grammatical parts, which is crucial for things like translating languages since computers need to get the structure right to translate words accurately from one language to another. Another key use of CFG parsing is in building compilers for programming languages. Compilers use CFG to dissect the code that programmers write, turning it into something a computer can understand and act on.\n",
    "\n",
    "Besides these, CFG parsing finds its place in various other areas such as:\n",
    "- Checking code for errors in programming tools.\n",
    "- Helping voice recognition systems understand what we say.\n",
    "- Improving writing software by checking for grammatical mistakes.\n",
    "- Analyzing complex mathematical formulas in scientific programs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The CYK Algorithm <a name=\"paragraph1\"></a>\n",
    "\n",
    "##### Chomsky Normal Form <a name=\"subparagraph11\"></a>\n",
    "Before delving into the algorithm, we would like to first touch on the concept of Chomsky Normal Form (CNF). It is a prerequisite for understanding the CYK algorithm, as the algorithm specifically requires grammars to be in CNF in order to be processed. \n",
    "\n",
    "CNF, developed by the well-known modern linguist Noam Chomsky, aims to simplify the rules of context-free\n",
    "grammars for more efficient parsing and algorithmic analysis. It is a specific method for expressing CFGs, wherein every production rule takes one of two forms: either a non-terminal symbol producing two other non-terminal symbols or a non-terminal symbol producing a single terminal symbol. This single terminal symbol may include epsilon, indicating the deletion of a sentence. \n",
    "\n",
    "$$\n",
    "A \\rightarrow BC\n",
    "$$\n",
    "$$\n",
    "A \\rightarrow a\n",
    "$$\n",
    "$$\n",
    "S \\rightarrow \\Epsilon\n",
    "$$\n",
    "*(Uppercase letters represent non-terminal symbols, and lowercase letters represent terminal symbols)*\n",
    "\n",
    "\n",
    "By unifying production rules in such a specific and clean form really simplifies the design and analysis of parsing\n",
    "algorithms like CYK. \n",
    "\n",
    "##### Converting CFGs into Chomsky Normal Form (CNF) <a name=\"subparagraph33\"></a>\n",
    "\n",
    "In CNF, each rule must either produce two non-terminal symbols or a single terminal symbol. Consider the grammars below.\n",
    "\n",
    "$$G1 = S \\rightarrow a, S \\rightarrow AZ, A \\rightarrow a, Z \\rightarrow z$$\n",
    "$$G2 = S \\rightarrow a, S \\rightarrow aZ, Z \\rightarrow a$$\n",
    "\n",
    "Grammar $G1$ is in CNF since the first, third, and fourth rules all produce a single terminal symbol and the second rule produces two non-terminal symbols. Grammar $G2$ is not in CNF since the rule $S \\rightarrow aZ$ contains a terminal symbol ($a$) followed by a non-terminal symbol ($Z$).\n",
    "\n",
    "To convert a CFG to CNF, follow these rules:\n",
    "\n",
    "1. **Eliminate the start symbol from right hand side (RHS)**: If there is a start symbol S in the RHS of any rule, create a new rule $S0 \\rightarrow S$ and replace the $S$ in the RHS with $S0$.\n",
    "\n",
    "2. **Eliminate Null Productions**: Remove any rules that produce an empty string, replacing them with alternative productions that achieve the same language representation without the null option.\n",
    "\n",
    "3. **Eliminate Unit Productions**: Replace rules that produce a single non-terminal with rules that produce terminals directly. For instance $A \\rightarrow B$ and $B \\rightarrow a$ can be replaced with $A \\rightarrow a$.\n",
    "\n",
    "4. **Ensure all rules with terminals in RHS have a single terminal**: Eliminate terminals from the RHS if they are with other terminals or non-terminals by decomposing into multiple rules. For example, if you have the rule $X \\rightarrow xY$ you can decompose it into $X \\rightarrow ZY$ and $Z \\rightarrow x$.\n",
    "\n",
    "5. **Ensure all rules with non-terminals in RHS have exactly two non-terminals** : Eliminate rules with more than two non-terminal symbols by decomposing them into multiple rules. For example, the rule $X \\rightarrow XYZ$ can be broken into $X \\rightarrow PZ$ and $P \\rightarrow XY$.\n",
    "\n",
    "Let's try an example. The grammar $S \\rightarrow \\epsilon, S \\rightarrow aSb$ generates the language $a^nb^n | n \\geq 0$.\n",
    "\n",
    "1. Eliminate start symbols from the right hand side.\n",
    "We can eliminate the S from the RHS by writing a new rule $S0 \\rightarrow S$ where S0 is our new start symbol.\n",
    "\n",
    "$$S \\rightarrow \\epsilon$$\n",
    "$$S \\rightarrow aSb$$\n",
    "$$S0 \\rightarrow S$$\n",
    "\n",
    "2. Eliminate Null Productions\n",
    "Let's remove the epsilon and add a rule to cover the case where the $S \\rightarrow \\epsilon$ would be used. If this rule were used, the $\\epsilon$ would replace the $T$ in $S \\rightarrow aTb$ leaving just the $a$ and $b$. We can replicate this behavior by declaring $S \\rightarrow ab$. Note that this does not cover the case where $n=0$. To cover this case, we need to add back in a rule $S \\rightarrow \\epsilon$.\n",
    "\n",
    "$$S \\rightarrow ab$$\n",
    "$$S \\rightarrow aSb$$\n",
    "$$S \\rightarrow \\epsilon$$\n",
    "$$S0 \\rightarrow S$$\n",
    "\n",
    "3. Eliminate Unit Productions\n",
    "We have one unit production in our grammar, $S0 \\rightarrow S$. We can fix this by explicitely defining what $S0$ can go to as $S0 \\rightarrow ab | aSb | \\epsilon$. Note that $S0$ can go to $\\epsilon$ to create the empty string, but $S$ no longer goes to $\\epsilon$ since we've replaced that case.\n",
    "\n",
    "$$S \\rightarrow ab | aSb$$\n",
    "$$S0 \\rightarrow ab | aSb | \\epsilon$$\n",
    "\n",
    "4. Ensure all rules with terminals in RHS have a single terminal\n",
    "The rules $S \\rightarrow aSb$ and $S \\rightarrow ab$ have multiple terminals and/or terminals with non-terminals, as do their $S0$ equivalents. We can decompose them by introducing new non-terminals, $A \\rightarrow a$ and $B \\rightarrow b$.\n",
    "\n",
    "$$S \\rightarrow AB | ASB$$\n",
    "$$S0 \\rightarrow AB | ASB | \\epsilon$$\n",
    "$$A \\rightarrow a$$\n",
    "$$B \\rightarrow b$$\n",
    "\n",
    "5. Ensure all rules with non-terminals in RHS have exactly two non-terminals\n",
    "The rules $S \\rightarrow ASB$ and $S0 \\rightarrow ASB$ have three non-terminals. We can introduce a new non-terminal to split the rule into $S \\rightarrow AR$ and $R \\rightarrow SB$ and same for $S0$.\n",
    "\n",
    "$$S \\rightarrow AB | AR$$\n",
    "$$S0 \\rightarrow AB | AR | \\epsilon$$\n",
    "$$R \\rightarrow SB$$\n",
    "$$A \\rightarrow a$$\n",
    "$$B \\rightarrow b$$\n",
    "\n",
    "After covering the five steps, we've converted our CFG into CNF! Note that this is not the only possible CNF for this language, there are many options that will work.\n",
    "Let's double check that our CNF CFG makes sense for the language $a^nb^n | n \\geq 0$ using our parser!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a found in ('A', {'a'}). Adding A to T[0][0]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), set()]\n",
      "[set(), set(), set(), set()]\n",
      "[set(), set(), set(), set()]\n",
      "[set(), set(), set(), set()]\n",
      "a found in ('A', {'a'}). Adding A to T[1][1]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), set()]\n",
      "[set(), {'A'}, set(), set()]\n",
      "[set(), set(), set(), set()]\n",
      "[set(), set(), set(), set()]\n",
      "b found in ('B', {'b'}). Adding B to T[2][2]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), set()]\n",
      "[set(), {'A'}, set(), set()]\n",
      "[set(), set(), {'B'}, set()]\n",
      "[set(), set(), set(), set()]\n",
      "b found in ('B', {'b'}). Adding B to T[3][3]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), set()]\n",
      "[set(), {'A'}, set(), set()]\n",
      "[set(), set(), {'B'}, set()]\n",
      "[set(), set(), set(), {'B'}]\n",
      "A found in T[1][1] and B found in T[2][2]. S : AB is valid. Adding S to T[1][2]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), set()]\n",
      "[set(), {'A'}, {'S'}, set()]\n",
      "[set(), set(), {'B'}, set()]\n",
      "[set(), set(), set(), {'B'}]\n",
      "A found in T[1][1] and B found in T[2][2]. T : AB is valid. Adding T to T[1][2]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), set()]\n",
      "[set(), {'A'}, {'S', 'T'}, set()]\n",
      "[set(), set(), {'B'}, set()]\n",
      "[set(), set(), set(), {'B'}]\n",
      "T found in T[1][2] and B found in T[3][3]. R : TB is valid. Adding R to T[1][3]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), set()]\n",
      "[set(), {'A'}, {'S', 'T'}, {'R'}]\n",
      "[set(), set(), {'B'}, set()]\n",
      "[set(), set(), set(), {'B'}]\n",
      "A found in T[0][0] and R found in T[1][3]. S : AR is valid. Adding S to T[0][3]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), {'S'}]\n",
      "[set(), {'A'}, {'S', 'T'}, {'R'}]\n",
      "[set(), set(), {'B'}, set()]\n",
      "[set(), set(), set(), {'B'}]\n",
      "A found in T[0][0] and R found in T[1][3]. T : AR is valid. Adding T to T[0][3]\n",
      "Parsing table:\n",
      "[{'A'}, set(), set(), {'S', 'T'}]\n",
      "[set(), {'A'}, {'S', 'T'}, {'R'}]\n",
      "[set(), set(), {'B'}, set()]\n",
      "[set(), set(), set(), {'B'}]\n",
      "Table filled. Checking if {'S', 'T'} (T[0][3]) contains S\n",
      "Can the string be derived? True\n"
     ]
    }
   ],
   "source": [
    "from CYKalgorithm import CYK_parse\n",
    "\n",
    "grammar_anbn = {\n",
    "    'S': {'AB', 'AR', 'e'}, #S: start sym. note that we've replaced S0 with S and S with T.\n",
    "    'T': {'AB', 'AR'},\n",
    "    'R': {'TB'},\n",
    "    'A': {'a'},\n",
    "    'B': {'b'}\n",
    "}\n",
    "\n",
    "# Example strings (TRUE)\n",
    "string_anbn = \"aabb\"\n",
    "string1_abnb = \"\"\n",
    "string2_anbn = \"ab\"\n",
    "\n",
    "# Example strings (FALSE)\n",
    "string3_anbn = \"abbb\"\n",
    "string4_anbn = \"b\"\n",
    "string5_anbn = \"abab\"\n",
    "\n",
    "table, result = CYK_parse(grammar_anbn, string_anbn) #change the string entry to other example string#_anbn to see different results, or add your own string!\n",
    "print(\"Can the string be derived?\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Code Architecture <a name=\"subparagraph12\"></a>\n",
    "Let's begin the code run-through of the algorithm with a high-level overview of the CYK algorithm's architecture:\n",
    "\n",
    "1. **Input and Grammar Preparation**: Before algorithm starts, the model implementer should prepare with an input string, which are sentences breaking down into words, and a set of grammar rules in Chomsky Normal Form (CNF).\n",
    "\n",
    "2. **Table Initialization**: A table (matrix) is then created with dimensions based on the length of the input string. This table will be used to store possible grammar derivations for substrings of the input.\n",
    "\n",
    "3. **Table Filling**: starting from the bottom level, the algorithm fills in the table and moves upward gradually. Each cell in the table represents a substring of the sentence and is filled with all possible grammar rules that could generate that substring. \n",
    "\n",
    "4. **Combining Substrings**: As it moves up the table, the algorithm combines smaller substrings that have already been matched with grammar rules to form larger substrings. It checks to see if these larger substrings can be generated by any of the CFG rules.\n",
    "\n",
    "5. **Final Verification**: Once the table is filled, the algorithm checks the top cell, which represents the entire string (sentence). If this cell contains the start symbol of the grammar, the string is considered derivable from the given grammar.\n",
    "\n",
    "6. **Result and Visualization**: Visualization of the table after each iteration can be used to enhance clarity and explainability of the processes for model implementers.\n",
    "\n",
    "##### Uses in the World <a name=\"subparagraph13\"></a>\n",
    "The CYK algorithm has several practical applications in the real world and is one of the most common CFG parsing algorithms. In computational linguistics, the CYK algorithm is used for parsing natural language sentences. It helps in syntactic analysis, which is fundamental for tasks like sentiment analysis (determining emotional tone behind a body of text), information extraction (finding specific information in a body of text), and automated question answering. This application is crucial for developing sophisticated AI chatbots and virtual assistants that can understand and respond to human language effectively.\n",
    "\n",
    "In the realm of programming, the CYK algorithm is employed in the development of compilers and interpreters for programming languages. Its ability to parse context-free grammars makes it useful for syntax analysis, ensuring that the code written by programmers adheres to the grammatical rules of the programming language. This aspect is vital for error detection and correction during software development.\n",
    "\n",
    "Additionally, in more specialized areas, the CYK algorithm can be applied in DNA sequencing and bioinformatics for analyzing and interpreting the genetic information contained in DNA sequences, where the algorithm helps in understanding the complex structures and patterns within genetic data. \n",
    "\n",
    "As we can see, the CYK algorithm has many uses in practical scenarios in computer science, math, technology, and even biology and other fields.\n",
    "\n",
    "##### Visual Walkthrough <a name=\"subparagraph14\"></a>\n",
    "\n",
    "Let's do a quick walkthrough of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Walkthrough <a name=\"paragraph2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanation of the `CYK_parse` Function\n",
    "\n",
    "The `CYK_parse` function Parses a string using the CYK algorithm to determine if it can be derived from a given context-free grammar in Chomsky Normal Form (CNF). It takes a grammar (in the form of a dictionary) and a string, returning a tuple with a 2D parsing table and a boolean indicating if the string can be derived from the start symbol 'S'.\n",
    "\n",
    "    def CYK_parse(grammar, string):\n",
    "\n",
    "To begin with, the function calculates the length of the input string (`n`) and the number of rules in the grammar (`r`). \n",
    "\n",
    "    n = len(string)\n",
    "    r = len(grammar)\n",
    "\n",
    "It then creates a 2D list (`T`), where each empty cell is a set meant to store non-terminal symbols during parsing.\n",
    "\n",
    "    T = [[set() for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "The parsing starts with substrings of length 1, which represent single characters of the input string.\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "For each character in the string, the function iterates over the grammar's rules. If a character is part of a rule's right-hand side `rhs`, it implies that the corresponding left-hand side `lhs` non-terminal can produce this character. This LHS is then added to the corresponding cell in `T`.\n",
    "\n",
    "        for lhs, rhs in grammar.items():\n",
    "            if string[i] in rhs: \n",
    "                T[i][i].add(lhs)\n",
    "\n",
    "Then this printed statement below displays which character from the string was found in the grammar rule and which non-terminal symbol was added to the table.\n",
    "\n",
    "                print(f\"{string[i]} found in {lhs, rhs}. Adding {lhs} to T[{i}][{i}]\")\n",
    "\n",
    "The table visualization is also updated for each iteration.\n",
    "\n",
    "                print_table(T)\n",
    "\n",
    "\n",
    "\n",
    "After handling single characters, the focus shifts to analyzing longer substrings (from 2 to `n`) of the input string. For each substring length `l`, and for each starting point `i`, it calculates the ending point `j`. \n",
    "     \n",
    "     for l in range(2, n + 1):\n",
    "        for i in range(n - l + 1):\n",
    "            j = i + l - 1\n",
    "\n",
    "It then iterates over all possible divisions of the substring (indexed by `k`) and checks if there's a production rule that can generate this substring. This is determined by checking if the LHS of a production rule can be formed by combining symbols found in smaller, already processed substrings of the current substring. \n",
    "            \n",
    "            for k in range(i, j):\n",
    "                for lhs, rhs in grammar.items():\n",
    "The loop structure `for lhs, rhs in grammar.items():` goes through each rule in the grammar, where `lhs` represents a non-terminal symbol and `rhs` represents the production rules associated with that non-terminal. \n",
    "\n",
    "Within this loop, another nested loop iterates over each production rule (`prod`) in `rhs`.\n",
    "                    \n",
    "                    for prod in rhs:\n",
    "\n",
    "To know if the non-terminal `lhs` can generate the substring spanning from `i` to `j`, these three conditions have to be met:\n",
    "\n",
    "1. The production rule `prod` should be binary, meaning a length of 2, aligning with the CNF requirement that rules are either of the form A → BC or A → a.\n",
    "2. `prod[0] in T[i][k]` ensures that the first non-terminal in the production rule can generate the substring at index `i` and ending at `k`.\n",
    "3. `prod[1] in T[k + 1][j]` checks if the second non-terminal can derive the substring from index `k + 1` to `j`.\n",
    "                    if len(prod) == 2 and prod[0] in T[i][k] and prod[1] in T[k + 1][j]:\n",
    "This step is repeated for all possible substrings and their divisions to build the parsing table based on the grammar's production rules.\n",
    "\n",
    "Then this printed statement below informs that the first symbol of the production rule (prod[0]) was found in the CYK table at position [i][k], and the second symbol (prod[1]) was found at [k+1][j]. The production rule being considered is thus valid, and will be added to the table\n",
    "\n",
    "                        print(f\"{prod[0]} found in T[{i}][{k}] and {prod[1]} found in T[{k+1}][{j}]. {lhs} : {prod[0]}{prod[1]} is valid. Adding {lhs} to T[{i}][{j}]\")\n",
    "\n",
    "If these conditions are met, then the non-terminal is added to the corresponding cell in table `T`.\n",
    "                        \n",
    "                        T[i][j].add(lhs)\n",
    "\n",
    "The table visualization is also updated for each iteration.\n",
    "\n",
    "                        print_table(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full code implementation is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CYKalgorithm import print_table #import the print table function\n",
    "\n",
    "def CYK_parse(grammar, string):\n",
    "    \"\"\"\n",
    "    Parses a string using the CYK algorithm to determine if it can be derived from a given context-free grammar in \n",
    "    Chomsky Normal Form (CNF).\n",
    "\n",
    "    Args:\n",
    "    grammar (dict): A dictionary representing the context-free grammar in CNF.\n",
    "    string (str): The string to be parsed.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple consists of\n",
    "        1. A 2D list representing the CYK parsing table, with each cell containing a set of non-terminal symbols.\n",
    "        2. A boolean value indicating whether the string can be derived from the start symbol ('S').\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(string)\n",
    "    r = len(grammar)\n",
    "    \n",
    "    # Create a 2D list table to store intermediate parsing results\n",
    "    T = [[set() for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "    # The table is filled starting from substrings of length 1, gradually moving to longer substrings\n",
    "    for i in range(n):\n",
    "    # loops over the characters of the input string\n",
    "        for lhs, rhs in grammar.items():\n",
    "        # loops over the items in the grammar dictionary--\n",
    "        # lhs:a non-terminal symbol; rhs: the set of production rules associated with the non-terminal symbol\n",
    "            if string[i] in rhs:\n",
    "            # if the ith character of the input string is part of the production rule set (rhs), \n",
    "            # the non-terminal symbol (lhs) can be used to derive this specific character according to the grammar rules\n",
    "                T[i][i].add(lhs)\n",
    "                # if the above is true, then non-terminal symbol (lhs) is added to the set at position [i][i] in the 2D list T\n",
    "                print(f\"{string[i]} found in {lhs, rhs}. Adding {lhs} to T[{i}][{i}]\")\n",
    "                # show character from the string was found in the grammar rule \n",
    "                # and which non-terminal symbol was added to the table\n",
    "                print_table(T)\n",
    "                # update the table visualization for each iteration\n",
    "\n",
    "    # Fill in the table for substrings of length 2 to n\n",
    "    for l in range(2, n + 1):\n",
    "    # loops over the possible lengths of substrings, starting from 2 up to the length of the input string\n",
    "        for i in range(n - l + 1):\n",
    "        #starting from 0 to \n",
    "            j = i + l - 1\n",
    "            # calculates the ending index (j) of the substring\n",
    "            for k in range(i, j):\n",
    "            # loops over the substring\n",
    "                for lhs, rhs in grammar.items():\n",
    "                # loops over the items in the grammar dictionary--\n",
    "                # lhs:a non-terminal symbol; rhs: the set of terminal symbols (production rules) associated with the non-terminal.\n",
    "                    for prod in rhs:\n",
    "                    # iterates over each production rule \"prod\" in the set rhs.\n",
    "                        if len(prod) == 2 and prod[0] in T[i][k] and prod[1] in T[k + 1][j]:\n",
    "                        # if these 3 conditions are met:\n",
    "                        # 1. the production rule prod is a binary\n",
    "                        # 2. the first symbol of prod can generate the substring from i to k\n",
    "                        # 3. the second symbol of prod can generate the substring from k + 1 to j\n",
    "                            print(f\"{prod[0]} found in T[{i}][{k}] and {prod[1]} found in T[{k+1}][{j}]. {lhs} : {prod[0]}{prod[1]} is valid. Adding {lhs} to T[{i}][{j}]\")\n",
    "                            # print out the progress\n",
    "                            T[i][j].add(lhs)\n",
    "                            # then add the non-terminal lhs, since it can generate the substring from i to j\n",
    "                            print_table(T)\n",
    "                            # update the table visualization for each iteration\n",
    "                            \n",
    "    # After the table is filled, the function checks if the start symbol ('S') is in the top-right cell of the table.\n",
    "    print(f\"Table filled. Checking if {T[0][n-1]} (T[0][{n-1}]) contains S\")\n",
    "    return T, 'S' in T[0][n - 1] \n",
    "    # the string can be derived from the start symbol according to the grammar if S (start) is an option in the top right corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of the `print_table` function\n",
    "\n",
    "The `print_table` function is designed to display the parsing table. This function accepts a 2D list (`table`) as its argument, where each cell in this list contains a set of symbols representing the results of the parsing process. \n",
    "\n",
    "    def print_table(table):\n",
    "\n",
    "It first prints a header - \"Parsing table:\" - and then iterates over each row of the table. During each iteration, it prints the row, displaying the sets of symbols contained in each cell. These symbols represent the non-terminal symbols that could potentially derive the corresponding substrings of the input string as per the grammar rules used in the parsing algorithm.\n",
    "\n",
    "        print(\"Parsing table:\")\n",
    "        for row in table:\n",
    "            print(row)\n",
    "The function is specifically designed for visualization, so it does not return any value but provides a clear representation of the current state of the parsing table, which helps with algoirthm explanation and verification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full code implementation is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(table):\n",
    "    \"\"\"\n",
    "    Prints the parsing table.\n",
    "\n",
    "    Args:\n",
    "    table (list of list of sets): A 2D list representing a table where each cell contains a set of symbols.\n",
    "                                  this is usually the parsing table generated from algorithms like CYK.\n",
    "\n",
    "    Returns:\n",
    "    - None: This function does not return values -- it solely prints and visualizes the table\n",
    "    \"\"\"\n",
    "    print(\"Parsing table:\")\n",
    "    for row in table:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing with Examples\n",
    "\n",
    "The following code snippet presents an example of a grammar rule in CNF, along with sample strings. Strings that adhere to these grammar rules would return TRUE when input into the function, whereas strings that do not conform to these rules would yield a FALSE result after being processed by the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example grammar in CNF\n",
    "# rules\n",
    "grammar = {\n",
    "    'S': {'AB'}, #S: start sym\n",
    "    'A': {'BB', 'a'},\n",
    "    'B': {'AB', 'b'}\n",
    "}\n",
    "\n",
    "# Example strings (TRUE)\n",
    "string = \"aabbb\"\n",
    "string1 = \"ab\"\n",
    "string2 = \"babbbb\"\n",
    "string3 = \"abbbbaabbab\"\n",
    "\n",
    "# Example strings (FALSE)\n",
    "string4 = \"\"\n",
    "string5 = \"b\"\n",
    "string6 = \"abababababaa\"\n",
    "\n",
    "\n",
    "# Parse the string\n",
    "table, result = CYK_parse(grammar, string3)\n",
    "\n",
    "# Print the result\n",
    "print(\"Can the string be derived?\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CYK Parsing on Natural Langauge<a name=\"paragraph3\"></a>\n",
    "\n",
    "##### The Benefits of CYK in NLP: a Brief Comparative Analysis with Transformers <a name=\"subparagraph31\"></a>\n",
    "Natural Language Processing (NLP) is a field is an interdisciplinary subfield of computer science and linguistics. that is primarily concerned with giving computers the ability to support and manipulate human language (*Wikipedia*). It encompasses a range of algorithmic tools for enabling computers to understand and process human language. Among these tools are transformers and the CYK algorithm.\n",
    "\n",
    "With the development and hype surrounding many large language models, transformers have garnered significant worldwide attention. While transformers are powerful tools in NLP, their approach to understanding language is based on statistical learning from large datasets. They are highly effective in many contexts *but might not always capture the syntactic structure of the language*. On the other hand, the CYK algorithm is another extreme. With its basis in formal grammar theory, it offers a strictly rule-based approach to parsing language. It intakes sentences that were broken down into their grammatical components, making CYK particularly valuable in applications such as in compiling programming languages or in certain aspects of natural language understanding, where parsing the exact structure of sentences is significant. \n",
    "\n",
    "Which brings us to the next topic: parts of speech.\n",
    "\n",
    "##### Part of Speech <a name=\"subparagraph32\"></a>\n",
    "\n",
    "In NLP and other linguistics related domains, identifying parts of speech correctly is fundamental. Parts of speech refer to categories that group words with similar grammatical properties. Common categories in English include nouns, pronouns, verbs, adjectives, adverbs, prepositions, conjunctions, and so on. These categories are significant to define because words in the same part of speech typically adhere to similar grammatical rules.\n",
    "\n",
    "Identifying parts of speech is a preliminary step in the CYK algorithm for NLP. This identification is essential for parsing sentences, where the structure of a sentence is being analyzed and understood. However, the CYK algorithm is not involved in the categorization of words into parts of speech. Instead, it relies on a given grammar that is already in CNF to parse sentences. The grammar must define how different parts of speech (like nouns, verbs, adjectives, etc.) combine to form valid sentence structures, so that the algorithm can determine whether the input string (sentence) is structurally valid based on the grammar rules.\n",
    "\n",
    "For example, consider a grammar in CNF that categorizes 'blue' as an adjective, 'bird' as a noun, 'sings' as a verb, 'happily' as an adverb, 'in' as a preposition, 'the' as a definite article, and 'spring' as a noun. The CYK algorithm, using this grammar, can analyze a sentence like 'The blue bird sings happily in the spring.' \n",
    "\n",
    "##### Writing CNF CFGs for Natural Language Parsing <a name=\"subparagraph33\"></a>\n",
    "\n",
    "Writing a Context-Free Grammar (CFG) in Chomsky Normal Form (CNF) for parsing natural language sentences involves restructuring complex linguistic rules into a binary format. For instance, consider the simple sentence \"The cat sleeps.\" A basic CFG to parse this might look like\n",
    "$$S \\rightarrow (NP)(VP)$$\n",
    "$$NP \\rightarrow (Det)(Noun)$$\n",
    "$$VP \\rightarrow Verb$$\n",
    "$$Det \\rightarrow the$$\n",
    "$$Noun \\rightarrow cat$$\n",
    "$$Verb \\rightarrow sleeps$$\n",
    "\n",
    "where NP, VP, Det, Noun, and Verb are are non-terminals and the, cat, and sleeps are all terminals.\n",
    "\n",
    "The abbreviations represent grammatical categories or parts of speech, where:\n",
    "\n",
    "**NP** stands for \"Noun Phrase.\" A noun phrase is a grammatical unit that can include a noun along with accompanying modifiers, such as articles, adjectives, pronouns, or other nouns. In the sentence \"The cat sleeps,\" \"The cat\" is an example of a noun phrase.\n",
    "\n",
    "**VP** represents \"Verb Phrase.\" A verb phrase consists of a main verb and, optionally, an object, and other modifiers. It can express actions, events, or states of being. In \"The cat sleeps,\" \"sleeps\" forms a simple verb phrase.\n",
    "\n",
    "**Det** is short for \"Determiner.\" Determiners are words that come before nouns and provide context in terms of definiteness, proximity, quantity, or ownership. Examples include \"the,\" \"a,\" \"this,\" \"those,\" \"many,\" etc. In the example sentence, \"The\" is a determiner.\n",
    "\n",
    "**Noun** is a word that identifies a person, place, thing, or idea. Nouns can function as the subject or object of a verb. In \"The cat sleeps,\" \"cat\" is the noun.\n",
    "\n",
    "**Verb** refers to a word that describes an action, state, or occurrence. Verbs form the main part of the predicate of a sentence. In the example, \"sleeps\" is the verb.\n",
    "\n",
    "Notice that our grammar is not yet in Chomsky Normal Form. We can convert it to CNF by applying the process described in *Converting CFGs into Chomsky Normal Form (CNF)*.\n",
    "\n",
    "##### Visual Walkthrough: Parsing a Sentence <a name=\"subparagraph34\"></a>\n",
    "Let's parse the sentence \"the cat sleeps\". \n",
    "\n",
    "1. We've already written our CFG for this sentence. As a reminder, the CFG is:\n",
    "$$S \\rightarrow (NP)(VP)$$\n",
    "$$NP \\rightarrow (Det)(Noun)$$\n",
    "$$VP \\rightarrow Verb$$\n",
    "$$Det \\rightarrow the$$\n",
    "$$Noun \\rightarrow cat$$\n",
    "$$Verb \\rightarrow sleeps$$\n",
    "\n",
    "2. Our CFG above is not quite in CNF. Let's convert it to CNF by applying the steps from *Converting CFGs into Chomsky Normal Form (CNF)*. One possible CNF CFG for this sentence is:\n",
    "\n",
    "$$S \\rightarrow (NP)(VP)$$\n",
    "$$NP \\rightarrow (Det)(Noun)$$\n",
    "$$VP \\rightarrow sleeps$$\n",
    "$$Det \\rightarrow the$$\n",
    "$$Noun \\rightarrow cat$$\n",
    "\n",
    "3. Using the CFG rules, we can build a parse tree for our sentence.\n",
    "\n",
    "To build the parse tree, we go through the rules in our grammar and add appropriate nodes or leaves to the tree. Nodes represent non-terminals and leaves represent terminals. We can start our tree with the root S. Following the first rule in our grammar, $S \\rightarrow (NP)(VP)$, we can add two nodes, NP and VP, off of S. Following the second rule, $NP \\rightarrow (Det)(Noun)$, we can add two nodes off of NP, Det and Noun. Lastly we can add our three leaves following the rules $VP \\rightarrow sleeps$, $Det \\rightarrow the$, and $Noun \\rightarrow cat$. The grey Verb node represents that the rule $VP \\rightarrow sleeps$ moves through the Verb non-terminal. It is included in grey here for clarity, but is not necessary for the tree.\n",
    "\n",
    "!['the cat sleeps' Parse Tree](parsetree_thecatsleeps.jpg)\n",
    "\n",
    "4. Using the CFG rules, we can build a chart for our sentence.\n",
    "\n",
    "To build the chart, we start with the terminals and build backwards using the rules of the grammar. If it helps, you can think of it as building our parse tree in reverse. The terminal 'the' goes to the non-terminal 'Det'. The terminal 'cat' goes to the non-terminal 'Noun'. The terminal 'sleeps' goes to the non-terminal 'VP'. On the next line, we look to see if there are any valid combinations of non-terminals. We can find that there is one valid combination; the non-terminals 'Det' and 'Noun' go back to the non-terminal 'NP'. There are no other valid combinations on this line so we move up to the next line. On the top line, we find the valid combination 'NP VP' which goes to 'S'. \n",
    "\n",
    "!['the cat sleeps' Chart](chart_thecatsleeps.jpg)\n",
    "\n",
    "5. Check if 'S' is present in the top left box on the chart.\n",
    "\n",
    "Once we complete our chart, we can check if 'S' is present in the top left box. If it is, then the string is valid for the grammar since that shows that we can get to the string we want starting from 'S' and going through a process of valid rules. Note that S could be present in other places on the chart, but we are only looking for its presence in the top left box since that box represents the highest level of rules, aka the start. Since our chart has 'S' present in the top left corner, the string \"the cat sleeps\" is valid for the given grammar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix <a name=\"appendix\"></a>\n",
    "\n",
    "##### Instructions for Running the Algorithm <a name=\"subappendix1\"></a>\n",
    "\n",
    "To run the CYK Algorithm implementation, fill in the lines 'grammar = ' and 'string = ' with any grammar and associated strings from the example section, then run the code chunk using the triangle shaped run button the top left of the code chunk. To create your own grammar, follow the rules in *Converting CFGs into Chomsky Normal Form (CNF)* to write a CNF grammar for a language of your choice.\n",
    "\n",
    "Note that this algorithm prints the chart in a slightly different format than the chart(s) presented above. See the image below to understand how to read the printed chart.\n",
    "\n",
    "\n",
    "\n",
    "##### CYK Implementation with Examples <a name=\"subappendix2\"></a>\n",
    "\n",
    "To see the full algorithm, check out the *Code Walkthrough* section or view the file \"CYKalgorithm.py\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CYKalgorithm import CYK_parse\n",
    "\n",
    "## Examples\n",
    "\n",
    "# Grammar\n",
    "\n",
    "# Strings (TRUE)\n",
    "\n",
    "# Strings (FALSE)\n",
    "\n",
    "\n",
    "# Grammar\n",
    "\n",
    "# Strings (TRUE)\n",
    "\n",
    "# Strings (FALSE)\n",
    "\n",
    "\n",
    "# Grammar\n",
    "\n",
    "# Strings (TRUE)\n",
    "\n",
    "# Strings (FALSE)\n",
    "\n",
    "\n",
    "## Create your own! \n",
    "\n",
    "# Create your own grammar\n",
    "\n",
    "grammar_diy = {\n",
    "\n",
    "}\n",
    "\n",
    "# Create your own strings (TRUE)\n",
    "string_diy = \"\"\n",
    "string_diy_1 = \"\"\n",
    "\n",
    "# Create your own strings (FALSE)\n",
    "string_diy_3 = \"\"\n",
    "string_diy_4 = \"\"\n",
    "\n",
    "## Parsing\n",
    "\n",
    "# Parse the string\n",
    "grammar = grammar_ #replace grammar_anbn with the name of example grammar you want to run\n",
    "string = string__1 #replace string_anbn_1 with the name of the example string you want to run (or type in your own string in the format \"your string\")\n",
    "\n",
    "table, result = CYK_parse(grammar, string)\n",
    "\n",
    "# Print the result\n",
    "print(\"Can the string be derived?\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sources <a name=\"sources\"></a>\n",
    "https://jayd.ml/algorithms/chomsky.html\n",
    "https://www.geeksforgeeks.org/converting-context-free-grammar-chomsky-normal-form/\n",
    "https://www.geeksforgeeks.org/what-is-context-free-grammar/\n",
    "https://www.geeksforgeeks.org/cyk-algorithm-for-context-free-grammar/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
